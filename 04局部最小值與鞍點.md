參考：[【機器學習2021】類神經網路訓練不起來怎麼辦 (一)： 局部最小值 (local minima) 與鞍點 (saddle point)](https://www.youtube.com/watch?v=QW6uINn7uGk&list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J&index=4)

## Gradient 卡在0是可能是因為 local minima(局部最小值)或saddle point(鞍點)
### 為什麼 Optimization 會失敗？

當我們發現 model 訓練不起來，一開始 loss 就很高時，可以猜測 **gradient 卡在 0**。

### 什麼情況下 gradient 是 0？

gradient 為 0 的情況主要有兩種：

#### 1. Local Minima（局部最小值）
- 在局部最小值點，所有方向的梯度都為 0
- 模型可能陷入次優解

#### 2. Saddle Point（鞍點）
- 在鞍點處，梯度同樣為 0
- 但並非真正的最小值點

### Critical Point（臨界點）

使 gradient 為 0 的情況統稱為 **Critical Point（臨界點）**。

### 重要性
知道在臨界點的情況是哪種類型，便可以決定接下來要採取的處理方式：
- 如果是 local minima：No way to go
- 如果是 saddle point：需要找到下降方向

<img width="896" height="670" alt="ep4-1" src="https://github.com/user-attachments/assets/1ba71c62-b959-4e07-9fbb-d46def46425c" />


## H 海塞矩陣（Hessian Matrix），會告訴我們參數可以update的方向

- 利用「在某一點完全相等」的條件，所以函數值相等、一階導數(Gradient)相等、二階導數(Hessian)也要相等。
- 只要算出Hessian這個矩陣，並且觀察其eigenvalue，便可知道現在的Critical point是什麼情況。
- 實作時，通常Eigenvalue都是有正有負，代表很少有Network真的走到Local minima。
<img width="894" height="666" alt="ep4-2" src="https://github.com/user-attachments/assets/8cf14e52-ce37-4cc0-9d59-9b878962cc89" />
<img width="896" height="671" alt="ep4-3" src="https://github.com/user-attachments/assets/75f25990-c20a-4155-937d-e12982440dc4" />
<img width="896" height="667" alt="ep4-4" src="https://github.com/user-attachments/assets/220f1ce7-480d-4a43-96f0-e6b2c583362c" />





